import cv2
import numpy as np
import easyocr
import re
import time
import datetime
import face_recognition
from skimage.metrics import structural_similarity as ssim
from PIL import ImageFont, ImageDraw, Image
import os

def preprocess_image(frame):
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(32, 32))
    enhanced = clahe.apply(frame)
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]])
    sharpened = cv2.filter2D(enhanced, -1, kernel)
    return sharpened

def extract_rrn(text):
    pattern = r'(\d{6})[-~]?(\d)'
    matches = re.findall(pattern, text)
    if matches:
        return matches[0][0], matches[0][1]
    else:
        return None, None

def is_adult(birth_str, code):
    try:
        year = int(birth_str[:2])
        month = int(birth_str[2:4])
        day = int(birth_str[4:6])
        code = int(code)

        if code in [1, 2]:
            year += 1900
        elif code in [3, 4]:
            year += 2000
        else:
            return False

        birth_date = datetime.datetime(year, month, day)
        today = datetime.datetime.today()

        age = today.year - birth_date.year - ((today.month, today.day) < (birth_date.month, birth_date.day))
        return age >= 20
    except:
        return False

def draw_korean_text(img_cv, text, pos=(50, 50), font_size=30, color=(0, 255, 0)):
    img_pil = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
    font = ImageFont.truetype(font_path, font_size)
    draw.text(pos, text, font=font, fill=color)
    img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    return img_cv

def run_id_ocr_stage(cap, roi_x, roi_y, roi_w, roi_h, reader):
    # Baseline ROI ìº¡ì²˜
    ret, frame = cap.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    baseline_roi = gray[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w]
    baseline_original = baseline_roi.copy()
    print("âœ… Baseline ROI ìº¡ì²˜ ì™„ë£Œ!")

    hold_start_time = None

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        original_frame = frame.copy()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        cv2.rectangle(frame, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (0, 255, 0), 2)
        frame = draw_korean_text(frame, "ì‹ ë¶„ì¦ì„ ë°•ìŠ¤ì— ìœ„ì¹˜ì‹œí‚¤ê³  2ì´ˆê°„ ëŒ€ê¸°í•´ì£¼ì„¸ìš”", (roi_x - 150, roi_y - 50), 30)

        current_roi = gray[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w]
        score, _ = ssim(baseline_original, current_roi, full=True)
        print(score)

        if score < 0.70:
            if hold_start_time is None:
                hold_start_time = time.time()
            else:
                duration = time.time() - hold_start_time
                if duration >= 2.0:
                    print("\nğŸ” SSIM ì¡°ê±´ ë§Œì¡±! OCR ë° ì–¼êµ´ ROI ì €ì¥ ì¤‘...")

                    cv2.imwrite("temp_roi.png", current_roi)
                    cv2.imwrite("temp_id_face.png", original_frame[roi_y:roi_y + roi_h, roi_x:roi_x + roi_w])

                    ocr_img = cv2.imread("temp_roi.png", cv2.IMREAD_GRAYSCALE)
                    processed = preprocess_image(ocr_img)
                    results = reader.readtext(processed, detail=0, paragraph=False)
                    full_text = ' '.join(results)

                    birth_num, code = extract_rrn(full_text)
                    if birth_num and code:
                        print(f"âœ… ì£¼ë¯¼ë²ˆí˜¸ ì•ìë¦¬: {birth_num}, ì½”ë“œ: {code}")
                        if is_adult(birth_num, code):
                            print("âœ… ì„±ì¸ì…ë‹ˆë‹¤. ê¸°ì¤€ ì–¼êµ´ ì¸ì½”ë”©ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

                            id_face_img = cv2.imread("temp_id_face.png")
                            id_face_locations = face_recognition.face_locations(id_face_img)
                            id_face_encodings = face_recognition.face_encodings(id_face_img, id_face_locations)

                            if id_face_encodings:
                                np.save("face_encoding.npy", id_face_encodings[0])
                                print("âœ… ê¸°ì¤€ ì–¼êµ´ ì¸ì½”ë”© íŒŒì¼(face_encoding.npy) ì €ì¥ ì™„ë£Œ.")

                                cv2.destroyAllWindows()  # OCR ì°½ ì™„ì „ ì¢…ë£Œ
                                return True
                            else:
                                print("âš ï¸ ì‹ ë¶„ì¦ì—ì„œ ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ ì¢…ë£Œ.")
                                cv2.destroyAllWindows()
                                return False
                        else:
                            print("âŒ ë¯¸ì„±ë…„ìì…ë‹ˆë‹¤. êµ¬ë§¤ ë¶ˆê°€.")
                            cv2.destroyAllWindows()
                            return False
                    else:
                        print("âŒ ì£¼ë¯¼ë²ˆí˜¸ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        cv2.destroyAllWindows()
                        return False

                    hold_start_time = None
        else:
            hold_start_time = None

        cv2.imshow("ID Verification", frame)
        if cv2.waitKey(1) == 27:
            break

    cv2.destroyAllWindows()
    return False

def run_face_verification_stage(cap):
    if not os.path.exists("face_encoding.npy"):
        print("âŒ face_encoding.npy íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € OCR ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")
        return

    id_face_encoding = np.load("face_encoding.npy")
    print("\nâœ… ì–¼êµ´ ì¸ì¦ ì°½ ì‹œì‘!")
    start_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame = draw_korean_text(frame, "ì–¼êµ´ì„ ì¸ì‹ì‹œì¼œ ì£¼ì„¸ìš”.", (400, 50), 32)

        elapsed = time.time() - start_time

        if elapsed >= 2.0:
            live_face_locations = face_recognition.face_locations(frame)
            live_face_encodings = face_recognition.face_encodings(frame, live_face_locations)

            if live_face_encodings:
                result = face_recognition.compare_faces([id_face_encoding], live_face_encodings[0], tolerance=0.6)
                if result[0]:
                    print("âœ… ì–¼êµ´ ì¸ì¦ ì„±ê³µ! ìµœì¢… ì¸ì¦ ì™„ë£Œ.")
                    frame = draw_korean_text(frame, "ì–¼êµ´ ì¸ì¦ ì„±ê³µ! ì¸ì¦ ì™„ë£Œ.", (300, 400), 32, color=(0, 255, 0))
                else:
                    print("âŒ ì–¼êµ´ ë¶ˆì¼ì¹˜. ì¸ì¦ ì‹¤íŒ¨.")
                    frame = draw_korean_text(frame, "ì–¼êµ´ ë¶ˆì¼ì¹˜. ì¸ì¦ ì‹¤íŒ¨.", (300, 400), 32, color=(0, 0, 255))
            else:
                print("âš ï¸ ì‹¤ì‹œê°„ ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        cv2.imshow("Face Verification", frame)
        if cv2.waitKey(1) == 27:
            break

    cv2.destroyAllWindows()

def main():
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    roi_x, roi_y, roi_w, roi_h = 440, 160, 400, 250
    reader = easyocr.Reader(['ko'], gpu=False, verbose=False)

    ocr_success = run_id_ocr_stage(cap, roi_x, roi_y, roi_w, roi_h, reader)

    time.sleep(1)

    if ocr_success:
        run_face_verification_stage(cap)
    else:
        print("âŒ ì–¼êµ´ ì¸ì¦ ë‹¨ê³„ë¡œ ì§„ì…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    cap.release()

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    if os.path.exists("temp_roi.png"):
        os.remove("temp_roi.png")
    if os.path.exists("temp_id_face.png"):
        os.remove("temp_id_face.png")

if __name__ == "__main__":
    main()
